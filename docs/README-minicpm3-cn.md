<div align="center">
<img src="../assets/minicpm_logo.png" width="500em" ></img> 
</div>

<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> | <a href="README-minicpm3-en.md">English</a>
    <p>
</h4>

# MiniCPM 3.0

MiniCPM 3.0 æ˜¯ä¸€ä¸ª 4B å‚æ•°é‡çš„è¯­è¨€æ¨¡å‹ï¼Œç›¸æ¯” MiniCPM1.0/2.0ï¼ŒåŠŸèƒ½æ›´åŠ å…¨é¢ï¼Œç»¼åˆèƒ½åŠ›å¤§å¹…æå‡ï¼Œå¤šæ•°è¯„æµ‹é›†ä¸Šçš„æ•ˆæœæ¯”è‚©ç”šè‡³è¶…è¶Šä¼—å¤š 7B-9B æ¨¡å‹ã€‚

* **æ”¯æŒå·¥å…·è°ƒç”¨ğŸ› ï¸ï¼ˆFunction Callingï¼‰å’Œä»£ç è§£é‡Šå™¨ğŸ’»ï¼ˆCode Interpreterï¼‰**ï¼š[Berkeley Function Calling Leaderboard (BFCL)](https://gorilla.cs.berkeley.edu/leaderboard.html) ä¸Šå–å¾— 9B è§„æ¨¡ä»¥ä¸‹ SOTAï¼Œè¶…è¶Š GLM-4-9B-Chatã€Qwen2-7B-Instructã€‚
* **è¶…å¼ºçš„æ¨ç†èƒ½åŠ›ğŸ§®**ï¼šæ•°å­¦èƒ½åŠ›æ–¹é¢ï¼Œ[MathBench](https://open-compass.github.io/MathBench/) ä¸Šçš„æ•ˆæœè¶…è¶Š GPT-3.5-Turbo ä»¥åŠå¤šä¸ª 7B-9B æ¨¡å‹ã€‚åœ¨éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§çš„ [LiveCodeBench](https://livecodebench.github.io/) ä¸Šï¼Œæ•ˆæœè¶…è¶Š Llama3.1-8B-Instructã€‚
* **å‡ºè‰²çš„ä¸­è‹±æ–‡æŒ‡ä»¤éµå¾ªèƒ½åŠ›ğŸ¤–**ï¼šè‹±æ–‡æŒ‡ä»¤éµå¾ª [IFEval](https://huggingface.co/datasets/google/IFEval)ã€ä¸­æ–‡æŒ‡ä»¤éµå¾ª [FollowBench-zh](https://huggingface.co/datasets/YuxinJiang/FollowBench) æ•ˆæœè¶…è¶Š GLM-4-9B-Chatã€Qwen2-7B-Instructã€‚
* **é•¿æ–‡æœ¬èƒ½åŠ›**ï¼šåŸç”Ÿæ”¯æŒ 32k ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œ32k é•¿åº¦å†…å¤§æµ·æé’ˆå…¨ç»¿ã€‚æå‡º [LLMxMapReduce](https://github.com/thunlp/LLMxMapReduce) ï¼Œç†è®ºå¯å¤„ç†çš„ä¸Šä¸‹æ–‡é•¿åº¦è¾¾åˆ° +âˆï¼Œåœ¨ç»¼åˆæ€§é•¿æ–‡æœ¬è¯„æµ‹åŸºå‡† [InfiniteBench](https://github.com/OpenBMB/InfiniteBench) å¹³å‡å¾—åˆ†è¶…è¶ŠGPT-4ã€KimiChatç­‰æ ‡æ†æ¨¡å‹ã€‚
* **RAGèƒ½åŠ›**ï¼šæˆ‘ä»¬å‘å¸ƒäº† [MiniCPM RAG å¥—ä»¶](https://huggingface.co/collections/openbmb/minicpm-rag-suite-66d976b4204cd0a4f8beaabb)ã€‚åŸºäº MiniCPM ç³»åˆ—æ¨¡å‹çš„ [MiniCPM-Embedding](https://huggingface.co/openbmb/MiniCPM-Embedding)ã€[MiniCPM-Reranker](https://huggingface.co/openbmb/MiniCPM-Reranker) åœ¨ä¸­æ–‡ã€ä¸­è‹±è·¨è¯­è¨€æ£€ç´¢æµ‹è¯•ä¸­å–å¾— SOTA è¡¨ç°ï¼›é’ˆå¯¹ RAG åœºæ™¯çš„ [MiniCPM3-RAG-LoRA](https://huggingface.co/openbmb/MiniCPM3-RAG-LoRA) åœ¨å¼€æ”¾åŸŸé—®ç­”ç­‰å¤šé¡¹ä»»åŠ¡ä¸Šè¶…è¶Š Llama3-8Bã€Baichuan2-13B ç­‰æ¨¡å‹ã€‚

## è¯„æµ‹ç»“æœ

### ç»¼åˆè¯„æµ‹

<table>
    <tr>
        <td>è¯„æµ‹é›†</td>
        <td>Qwen2-7B-Instruct</td>
        <td>GLM-4-9B-Chat</td>
        <td>Gemma2-9B-it</td>
        <td>Llama3.1-8B-Instruct</td>
        <td>GPT-3.5-Turbo-0125</td>
        <td>Phi-3.5-mini-Instruct(3.8B)</td>
        <td>MiniCPM3-4B </td>
    </tr>
    <tr>
        <td colspan="15" align="left"><strong>è‹±æ–‡èƒ½åŠ›</strong></td>
    </tr>
    <tr>
        <td>MMLU</td>
        <td>70.5</td>
        <td>72.4</td>
        <td>72.6</td>
        <td>69.4</td>
        <td>69.2</td>
        <td>68.4</td>
        <td>67.2 </td>
    </tr>
    <tr>
        <td>BBH</td>
        <td>64.9</td>
        <td>76.3</td>
        <td>65.2</td>
        <td>67.8</td>
        <td>70.3</td>
        <td>68.6</td>
        <td>70.2 </td>
    </tr>
    <tr>
        <td>MT-Bench</td>
        <td>8.41</td>
        <td>8.35</td>
        <td>7.88</td>
        <td>8.28</td>
        <td>8.17</td>
        <td>8.60</td>
        <td>8.41 </td>
    </tr>
    <tr>
        <td>IFEVAL (Prompt Strict-Acc.)</td>
        <td>51.0</td>
        <td>64.5</td>
        <td>71.9</td>
        <td>71.5</td>
        <td>58.8</td>
        <td>49.4</td>
        <td>68.4 </td>
    </tr>
    <tr>
        <td colspan="15" align="left"><strong>ä¸­æ–‡èƒ½åŠ›</strong></td>
    </tr>
    <tr>
        <td>CMMLU</td>
        <td>80.9</td>
        <td>71.5</td>
        <td>59.5</td>
        <td>55.8</td>
        <td>54.5</td>
        <td>46.9</td>
        <td>73.3 </td>
    </tr>
    <tr>
        <td>CEVAL</td>
        <td>77.2</td>
        <td>75.6</td>
        <td>56.7</td>
        <td>55.2</td>
        <td>52.8</td>
        <td>46.1</td>
        <td>73.6 </td>
    </tr>
    <tr>
        <td>AlignBench v1.1</td>
        <td>7.10</td>
        <td>6.61</td>
        <td>7.10</td>
        <td>5.68</td>
        <td>5.82</td>
        <td>5.73</td>
        <td>6.74 </td>
    </tr>
    <tr>
        <td>FollowBench-zh (SSR)</td>
        <td>63.0</td>
        <td>56.4</td>
        <td>57.0</td>
        <td>50.6</td>
        <td>64.6</td>
        <td>58.1</td>
        <td>66.8 </td>
    </tr>
    <tr>
        <td colspan="15" align="left"><strong>æ•°å­¦èƒ½åŠ›</strong></td>
    </tr>
    <tr>
        <td>MATH</td>
        <td>49.6</td>
        <td>50.6</td>
        <td>46.0</td>
        <td>51.9</td>
        <td>41.8</td>
        <td>46.4</td>
        <td>46.6 </td>
    </tr>
    <tr>
        <td>GSM8K</td>
        <td>82.3</td>
        <td>79.6</td>
        <td>79.7</td>
        <td>84.5</td>
        <td>76.4</td>
        <td>82.7</td>
        <td>81.1 </td>
    </tr>
    <tr>
        <td>MathBench</td>
        <td>63.4</td>
        <td>59.4</td>
        <td>45.8</td>
        <td>54.3</td>
        <td>48.9</td>
        <td>54.9</td>
        <td>65.6 </td>
    </tr>
    <tr>
        <td colspan="15" align="left"><strong>ä»£ç èƒ½åŠ›</strong></td>
    </tr>
    <tr>
        <td>HumanEval+</td>
        <td>70.1</td>
        <td>67.1</td>
        <td>61.6</td>
        <td>62.8</td>
        <td>66.5</td>
        <td>68.9</td>
        <td>68.3 </td>
    </tr>
    <tr>
        <td>MBPP+</td>
        <td>57.1</td>
        <td>62.2</td>
        <td>64.3</td>
        <td>55.3</td>
        <td>71.4</td>
        <td>55.8</td>
        <td>63.2 </td>
    </tr>
    <tr>
        <td>LiveCodeBench v3</td>
        <td>22.2</td>
        <td>20.2</td>
        <td>19.2</td>
        <td>20.4</td>
        <td>24.0</td>
        <td>19.6</td>
        <td>22.6 </td>
    </tr>
    <tr>
        <td colspan="15" align="left"><strong>å·¥å…·è°ƒç”¨èƒ½åŠ›</strong></td>
    </tr>
    <tr>
        <td>BFCL v2</td>
        <td>71.6</td>
        <td>70.1</td>
        <td>19.2</td>
        <td>73.3</td>
        <td>75.4</td>
        <td>48.4</td>
        <td>76.0 </td>
    </tr>
    <tr>
        <td colspan="15" align="left"><strong>ç»¼åˆèƒ½åŠ›</strong></td>
    </tr>
    <tr>
        <td>å¹³å‡åˆ†</td>
        <td>65.3</td>
        <td>65.0</td>
        <td>57.9</td>
        <td>60.8</td>
        <td>61.0</td>
        <td>57.2</td>
        <td><strong>66.3</strong></td>
    </tr>
</table>

### å·¥å…·è°ƒç”¨èƒ½åŠ›

æˆ‘ä»¬åœ¨ [Berkeley Function Calling Leaderboard (BFCL)](https://gorilla.cs.berkeley.edu/leaderboard.html) ä¸Šæµ‹è¯•äº†æ¨¡å‹çš„å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼ŒMiniCPM3-4B åœ¨è¯¥æ¦œå•ä¸Šçš„è¡¨ç°è¶…è¶Šäº†å¤šä¸ª 7B-9B å‚æ•°é‡çš„æ¨¡å‹ï¼Œä¼˜äº GPT-3.5-Turbo-0125ã€‚

<table>
    <tr>
        <td>æ¨¡å‹</td>
        <td>æ€»ä½“å‡†ç¡®ç‡</td>
        <td>AST Summary</td>
        <td>Exec Summary</td>
        <td>Irrelevance Detection</td>
        <td>Relevance Detection </td>
    </tr>
    <tr>
        <td>MiniCPM3-4B</td>
        <td>76.03%</td>
        <td>68.55%</td>
        <td>85.54%</td>
        <td>53.71%</td>
        <td>90.24% </td>
    </tr>
    <tr>
        <td>Llama3.1-8B-Instruct</td>
        <td>73.28%</td>
        <td>64.61%</td>
        <td>86.48%</td>
        <td>43.12%</td>
        <td>85.37% </td>
    </tr>
    <tr>
        <td>Qwen2-7B-Instruct</td>
        <td>71.61%</td>
        <td>65.71%</td>
        <td>79.57%</td>
        <td>44.70%</td>
        <td>90.24% </td>
    </tr>
    <tr>
        <td>GLM-4-9B-Chat</td>
        <td>70.08%</td>
        <td>60.69%</td>
        <td>80.02%</td>
        <td>55.02%</td>
        <td>82.93% </td>
    </tr>
    <tr>
        <td>Phi-3.5-mini-instruct</td>
        <td>48.44%</td>
        <td>38.89%</td>
        <td>54.04%</td>
        <td>46.78%</td>
        <td>65.85% </td>
    </tr>
    <tr>
        <td>Gemma2-9B-it</td>
        <td>19.18%</td>
        <td>5.41%</td>
        <td>18.50%</td>
        <td>88.88%</td>
        <td>7.32%</td>
    </tr>
</table>

### é•¿æ–‡æœ¬èƒ½åŠ›

åœ¨ 32k çš„ä¸Šä¸‹æ–‡é•¿åº¦è¿›è¡Œ[å¤§æµ·æé’ˆ](https://github.com/gkamradt/LLMTest_NeedleInAHaystack)æµ‹è¯•ï¼Œç»“æœå¦‚ä¸‹å›¾ï¼š

![needle](../assets/minicpm3/eval_needle.jpeg)

åŒæ—¶æˆ‘ä»¬æå‡º[LLMxMapReduce](https://github.com/thunlp/LLMxMapReduce)ï¼Œåˆ©ç”¨åˆ†æ²»çš„ç­–ç•¥ï¼Œç†è®ºä¸Šå¯ä»¥å¤„ç†æ— é™é•¿åº¦çš„æ–‡æœ¬ã€‚æˆ‘ä»¬åœ¨[InfiniteBench](https://github.com/OpenBMB/InfiniteBench)ä¸Šæµ‹è¯•äº†æ¨¡å‹çš„é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›ï¼Œåœ¨LLMxMapReduceæ¡†æ¶çš„åŠ æŒä¸‹ï¼ŒMiniCPM3-4Båœ¨è¿™ä¸ªæ¦œå•çš„å¹³å‡å¾—åˆ†èƒ½å¤Ÿè¶…è¶Š GPT-4ã€KimiChat ç­‰æ ‡æ†æ¨¡å‹ã€‚

|                               | Context length| Qwen2-70b | Kimi-Chat(2024.06) | GPT-4 (From InfiniteBench) | MiniCPM 3.0 x MR | Qwen2-70b x MR | Llama3-70bx MR |
| ----------------------------- | ---------- | --------- | ------------------ | -------------------------- | --------------- | ------------ | ------------- |
| Math.Find                     | 87.9k      | 59.71%    | 18.57%             | 60.00%                     | 83.43%          | 54.29%       | **91.43%**        |
| Retrieve.KV                   | 89.9k      | 29.00%    | 69.20%             | 89.00%                     | 93.80%          | 98.80%       | **98.89%**        |
| En.Dia                        | 103.6K     | 23.00%    | 23.00%             | 7.50%                      | 12.50%          | **46.50%**       | 17.50%        |
| Code.Debug                    | 114.7k     | 45.43%    | 38.32%             | 54.31%                     | 25.63%          | 54.82%       | **62.94%**       |
| Retrieve.Number               | 122.4k     | **100.00%**  | 97.45%             | **100.00%**                   | 99.32%          | **100.00%**     | 99.79%        |
| Retrieve.PassKey              | 122.4k     | **100.00%**   | 99.32%             | **100.00%**                   | 98.81%          | **100.00%**     | **100.00%**      |
| En.Sum                        | 171.5K     | 31.85%    | 29.94%             | 14.73%                     | 25.89%          | **32.39%**       | 30.63%        |
| En.MC                         | 184.4k     | 81.66%    | 79.91%             | 68.12%                     | 66.38%          |**83.84%**      | 82.10%        |
| En.QA        | 192.6k     | 21.97%    | 18.80%             | 22.44%                     | 28.39%          | 23.13%       | **34.70%**      |
| Zh.QA        | 2068.6k    | 21.40%    | 19.84%             | **25.96%**                    | 23.66%          | 19.10%       | N/A           |
| avg w/o Zh.QA | /          | 51.92%    | 52.96%             | 55.33%                     | 59.29%          | 64.98%       | **68.64%**        |
| avg                           | /          | 48.86%    | 49.65%             | 52.39%                     | 55.55%          | **60.39%**       | N/A           |

## æ¨¡å‹æ¨ç†

### Huggingface
```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
torch.manual_seed(0)

path = 'openbmb/MiniCPM3-4B'
tokenizer = AutoTokenizer.from_pretrained(path)
model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map='cuda', trust_remote_code=True)

responds, history = model.chat(tokenizer, "è¯·å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ï¼Œè¯¦ç»†ä»‹ç»äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•å’Œéšæ‚£ã€‚", temperature=0.7, top_p=0.7)
print(responds)
```

### SGLangï¼ˆæ¨èï¼‰
* å®‰è£…

å‚è€ƒ SGLang [å®˜æ–¹ä»“åº“](ttps://github.com/sgl-project/sglang)ï¼Œé€šè¿‡*æºç *å®‰è£…æœ€æ–°ç‰ˆæœ¬ã€‚

* å¯åŠ¨æ¨ç†æœåŠ¡
```shell
python -m sglang.launch_server --model openbmb/MiniCPM3-4B --trust-remote-code --port 30000 --chat-template chatml
```

* ä½¿ç”¨ç¤ºä¾‹
```python
from sglang import function, system, user, assistant, gen, set_default_backend, RuntimeEndpoint

@function
def multi_turn_question(s, question_1, question_2):
    s += user(question_1)
    s += assistant(gen("answer_1", max_tokens=1024))
    s += user(question_2)
    s += assistant(gen("answer_2", max_tokens=1024))

set_default_backend(RuntimeEndpoint("http://localhost:30000"))

state = multi_turn_question.run(
    question_1="ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½",
    question_2="å†™ä¸€ç¯‡å…³äºå®ƒçš„æ–‡ç« ",
)

for m in state.messages():
    print(m["role"], ":", m["content"])
```

### vLLM
* å®‰è£… vllm
  ```shell
  pip install "vllm>=0.6.2"
  ```
* æ¨ç†
  ```python
  from transformers import AutoTokenizer
  from vllm import LLM, SamplingParams

  model_name = "openbmb/MiniCPM3-4B"
  prompt = [{"role": "user", "content": "è¯·å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ï¼Œè¯¦ç»†ä»‹ç»äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•å’Œéšæ‚£ã€‚"}]

  tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
  input_text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)

  llm = LLM(model=model_name,
      trust_remote_code=True,
      tensor_parallel_size=1
  )
  sampling_params = SamplingParams(top_p=0.7, temperature=0.7, max_tokens=1024)

  outputs = llm.generate(prompts=input_text, sampling_params=sampling_params)

  print(outputs[0].outputs[0].text)
  ```

### llama.cpp

æˆ‘ä»¬æä¾›äº† MiniCPM3 çš„ [GGUF ç‰ˆæœ¬](https://huggingface.co/openbmb/MiniCPM3-4B-GGUF)ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ llama.cpp æ¨ç†ã€‚

* å®‰è£… llama.cpp
  ```shell
    git clone https://github.com/ggerganov/llama.cpp
    cd llama.cpp
    make 
  ```
* æ¨ç†
  ```shell
  ./llama-cli -c 1024 -m minicpm3-4b-fp16.gguf -n 1024 --top-p 0.7 --temp 0.7 --prompt "<|im_start|>user\nè¯·å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ–‡ç« ï¼Œè¯¦ç»†ä»‹ç»äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•å’Œéšæ‚£ã€‚<|im_end|>\n<|im_start|>assistant\n"
  ```

## æ¨¡å‹å¾®è°ƒ
### LLaMA-Factory
ç›®å‰æ¨¡å‹å¾®è°ƒæ”¯æŒ [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)ï¼Œä½¿ç”¨æ–¹æ³•å‚è€ƒ [LLaMA-Factory å¾®è°ƒ](https://modelbest.feishu.cn/docx/Z7USdW4lloZzkZxQ14icJ3senjb?from=from_copylink)ã€‚

## è¿›é˜¶åŠŸèƒ½

å¯¹äºä»¥ä¸‹è¿›é˜¶åŠŸèƒ½ï¼Œæˆ‘ä»¬çš„æ ·ä¾‹ä»£ç ä¸­ä½¿ç”¨ [vLLM](#vllm) è¿›è¡Œæ¨ç†ã€‚

### å·¥å…·è°ƒç”¨

æˆ‘ä»¬æä¾›äº†ä½¿ç”¨ MiniCPM3 è°ƒç”¨å·¥å…·çš„ç¤ºä¾‹ä»£ç ï¼š

```bash
cd demo/minicpm3/function_call
python function_call.py
```

å¦‚æœä½ æƒ³å¯åŠ¨ä¸€ä¸ªèƒ½å¤Ÿè°ƒç”¨å·¥å…·çš„æ¨ç†æœåŠ¡ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```bash
cd demo/minicpm3/function_call
pip install -r requirements.txt
python openai_api_server.py \
    --model openbmb/MiniCPM3-4B \
    --served-model-name MiniCPM3-4B \
    --chat-template chatml.jinja \
    --dtype auto \
    --api-key token-abc123 \
    --tensor-parallel-size 1 \
    --trust-remote-code
```

ä¸‹é¢æ˜¯ä¸€ä¸ªè°ƒç”¨æœç´¢å·¥å…·å›ç­”é—®é¢˜çš„æ¼”ç¤ºï¼š

![function_call](../assets/minicpm3/function_call.gif)

### ä»£ç è§£é‡Šå™¨

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ª MiniCPM3 ä½¿ç”¨ä»£ç è§£é‡Šå™¨çš„ç¤ºä¾‹ä»£ç ï¼š

```bash
cd demo/minicpm3/code_interpreter
pip install -r requirements.txt
python code_interpreter.py openbmb/MiniCPM3-4B
```

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ä»£ç è§£é‡Šå™¨ç”ŸæˆäºŒç»´ç çš„æ¼”ç¤ºï¼š

![code_interpreter](../assets/minicpm3/code_interpreter.gif)
